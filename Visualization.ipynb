{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KeplerMapper visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "col_names = [\"date\", \"views\", \"tags\", \"title\", \"text\"]\n",
    "with open(\"956-1010.csv\", \"r\", encoding=\"utf-8\") as data_file:\n",
    "    df = pd.read_csv(data_file, delimiter=\";\", names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'По информации Лайфа, десять москвичей получили тяжёлые травмы из-за обморожений и переохлаждения и были доставлены в больницы в Москве.Девять человек были госпитализированы в столице с обморожениями разной степени, а ещё один — с переохлаждением.— Четверо пострадавших были доставлены в больницы из Центрального административного округа Москвы, ещё по двое пострадавших оказались на севере и на западе столицы, — рассказал источник Лайфа, — также по одному пострадавшему от морозов приходится на ВАО И СЗАО.Одна из госпитализированных — 12-летняя девочка, она поступила в больницу с Крымского вала с обморожением пальцев.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df[df[\"tags\"].str.contains(\"происшествия\") == True]\n",
    "text_1 = texts.head(10).text.values[8].replace(u'\\xa0', u' ')\n",
    "text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Представленный аксессуар крепится к верхней части смартфона или планшета на платформе ОС Android и достаточно компактен для того, чтобы носить его с собой. Устройство имеет два инфракрасных датчика, датчик цвета и два инфракрасных лазерных прожектора, которые применяются для трёхмерного сканирования объекта.    Для создания 3D-модели своего лица пользователю достаточно просто медленно повернуть голову слева направо. Весь процесс занимает около 20 секунд. Результат сохраняется в стандартном формате .obj, что позволяет использовать полученную модель в других проектах или даже распечатать её на 3D-принтере.    Как отмечается, в настоящий момент устройство находится в стадии разработки, однако первые коммерческие модели могут появиться на рынке уже в конце 2017 года по цене около $300 (примерно 18 тыс. руб.).'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df[df[\"tags\"].str.contains(\"технологии\") == True]\n",
    "text_2 = texts.head(10).text.values[2].replace(u'\\xa0', u' ')\n",
    "text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ariel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from elmo_helpers import *\n",
    "from smart_open import open\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def parse(text, elmo_path):\n",
    "    data_path = input\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    sentences = [tokenize(s) for s in sentences]\n",
    "\n",
    "    print('=====')\n",
    "    print('%d sentences total' % len(sentences))\n",
    "    print('=====')\n",
    "\n",
    "    batcher, sentence_character_ids, elmo_sentence_input = load_elmo_embeddings(elmo_path)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        elmo_vectors = get_elmo_vectors(\n",
    "            sess, sentences, batcher, sentence_character_ids, elmo_sentence_input)\n",
    "\n",
    "    print('ELMo embeddings are ready')\n",
    "    print('Tensor shape:', elmo_vectors.shape)\n",
    "\n",
    "    cropped_vectors = []\n",
    "    for vect, sent in zip(elmo_vectors, sentences):\n",
    "        cropped_vector = vect[:len(sent), :]\n",
    "        cropped_vectors.append(cropped_vector)\n",
    "\n",
    "    return cropped_vectors, sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1126 17:17:56.960733  4396 deprecation_wrapper.py:119] From F:\\Study\\NIS_Krylov\\simple_elmo\\elmo_helpers.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1126 17:17:56.971708  4396 deprecation_wrapper.py:119] From F:\\Study\\NIS_Krylov\\simple_elmo\\bilm\\model.py:276: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1126 17:17:56.972706  4396 deprecation_wrapper.py:119] From F:\\Study\\NIS_Krylov\\simple_elmo\\bilm\\model.py:333: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W1126 17:17:56.986665  4396 deprecation_wrapper.py:119] From F:\\Study\\NIS_Krylov\\simple_elmo\\bilm\\model.py:378: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "8 sentences total\n",
      "=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 17:17:57.681800  4396 deprecation.py:323] From F:\\Study\\NIS_Krylov\\simple_elmo\\bilm\\model.py:522: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W1126 17:17:57.692748  4396 deprecation_wrapper.py:119] From F:\\Study\\NIS_Krylov\\simple_elmo\\bilm\\model.py:566: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
      "\n",
      "W1126 17:17:57.692748  4396 deprecation.py:323] From F:\\Study\\NIS_Krylov\\simple_elmo\\bilm\\model.py:567: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W1126 17:17:57.739655  4396 deprecation.py:506] From C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1126 17:17:58.035859  4396 deprecation.py:506] From C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1126 17:17:58.518540  4396 deprecation.py:323] From C:\\Users\\ariel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1126 17:17:58.537517  4396 deprecation_wrapper.py:119] From F:\\Study\\NIS_Krylov\\simple_elmo\\bilm\\model.py:591: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "W1126 17:17:58.544498  4396 deprecation_wrapper.py:119] From F:\\Study\\NIS_Krylov\\simple_elmo\\bilm\\model.py:536: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
      "\n",
      "W1126 17:17:59.842029  4396 deprecation_wrapper.py:119] From F:\\Study\\NIS_Krylov\\simple_elmo\\bilm\\elmo.py:92: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "Sentences in this batch: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo embeddings are ready\n",
      "Tensor shape: (8, 30, 1024)\n"
     ]
    }
   ],
   "source": [
    "vec, original_data = parse(test_text, \"195\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 1024)\n"
     ]
    }
   ],
   "source": [
    "stacked_vec = np.vstack(vec)\n",
    "print(stacked_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text = np.hstack(original_data)\n",
    "len(original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeplerMapper()\n",
      "..Composing projection pipeline of length 1:\n",
      "\tProjections: Isomap(eigen_solver='auto', max_iter=None, n_components=2, n_jobs=-1,\n",
      "       n_neighbors=5, neighbors_algorithm='auto', path_method='auto', tol=0)\n",
      "\tDistance matrices: False\n",
      "\tScalers: None\n",
      "..Projecting on data shaped (113, 1024)\n",
      "\n",
      "..Projecting data using: \n",
      "\tIsomap(eigen_solver='auto', max_iter=None, n_components=2, n_jobs=-1,\n",
      "       n_neighbors=5, neighbors_algorithm='auto', path_method='auto', tol=0)\n",
      "\n",
      "SHAPE (113, 2)\n"
     ]
    }
   ],
   "source": [
    "import kmapper as km\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mapper = km.KeplerMapper(verbose=2)\n",
    "\n",
    "projected_X = mapper.fit_transform(stacked_vec,\n",
    "    projection=[Isomap(n_components=2, n_jobs=-1)],\n",
    "    scaler=[None, None, MinMaxScaler()])\n",
    "\n",
    "print(\"SHAPE\",projected_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping on data shaped (113, 2) using lens shaped (113, 2)\n",
      "\n",
      "Minimal points in hypercube before clustering: 3\n",
      "Creating 100 hypercubes.\n",
      "Cube_0 is empty.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "Cube_2 is empty.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "Cube_5 is empty.\n",
      "\n",
      "Cube_6 is empty.\n",
      "\n",
      "Cube_7 is empty.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "Cube_9 is empty.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "Cube_17 is empty.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "Cube_26 is empty.\n",
      "\n",
      "Cube_27 is empty.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "Cube_34 is empty.\n",
      "\n",
      "Cube_35 is empty.\n",
      "\n",
      "Cube_36 is empty.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "Cube_46 is empty.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "Cube_56 is empty.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "Cube_64 is empty.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "Cube_67 is empty.\n",
      "\n",
      "Cube_68 is empty.\n",
      "\n",
      "Cube_69 is empty.\n",
      "\n",
      "Cube_70 is empty.\n",
      "\n",
      "Cube_71 is empty.\n",
      "\n",
      "Cube_72 is empty.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "   > Found 3 clusters.\n",
      "\n",
      "Cube_75 is empty.\n",
      "\n",
      "\n",
      "Created 288 edges and 162 nodes in 0:00:00.045877.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "graph = mapper.map(projected_X,\n",
    "                   clusterer=cluster.AgglomerativeClustering(n_clusters=3,\n",
    "                                                             linkage=\"complete\",\n",
    "                                                             affinity=\"cosine\"),\n",
    "                   overlap_perc=0.47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote visualization to: технологии.html\n"
     ]
    }
   ],
   "source": [
    "html = mapper.visualize(graph,\n",
    "                        lens=projected_X,\n",
    "                        lens_names=[\"ISOMAP1\", \"ISOMAP2\"],\n",
    "                        path_html=\"технологии.html\",\n",
    "                        X=stacked_vec,\n",
    "                        X_names=original_text,\n",
    "                        title=\"технологии\",\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
